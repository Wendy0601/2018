{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import *\n",
    "from numpy import dot, multiply, diag, power\n",
    "from numpy import pi, exp, sin, cos, cosh, tanh, real, imag\n",
    "from numpy.linalg import inv, eig, pinv,norm\n",
    "from scipy.linalg import svd, svdvals\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from functools import partial\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "from __future__ import print_function\n",
    "from sklearn import preprocessing  \n",
    "from sklearn import metrics \n",
    "import scipy.io as sio\n",
    "from xlrd import open_workbook \n",
    "import time  \n",
    "import re\n",
    "def save_npy_data():\n",
    "    rootpath = 'E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/sub_features/one_sec'\n",
    "    names = 'noise_level_'\n",
    "    for i in range(1,11): \n",
    "        dataname = names + str(10*i)\n",
    "        pathname = os.path.join(rootpath,dataname)\n",
    "        data = sio.loadmat(pathname)\n",
    "        testX_pred =  data['testX_pred_noise']\n",
    "        testX_pred = np.reshape(testX_pred,(322,9,3,1))\n",
    "        Energy_pred = data['Energy_pred_noise']\n",
    "        Energy_pred = np.reshape(Energy_pred,(322,9,2,1))\n",
    "        print (np.shape(testX_pred))\n",
    "        print (np.shape(Energy_pred))\n",
    "        noisename = names + str(10*i)\n",
    "        savepath = os.path.join(rootpath, dataname+'/testX_pred.npy')\n",
    "        np.save(savepath,testX_pred)\n",
    "        Esavepath = os.path.join(rootpath, dataname+'/Energy_pred.npy')\n",
    "        np.save(Esavepath,Energy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file 'E:/05_research/04_deep_learning_model/Save_parameters/modelA/Best_noise_model/modelA_snr50_fully'...\n",
      "INFO:tensorflow:Restoring parameters from E:/05_research/04_deep_learning_model/Save_parameters/modelA/Best_noise_model/modelA_snr50_fully\n",
      "Loading validation data...\n",
      "Validating model...\n",
      "LT: 81.44329896907216\n",
      "GT: 82.17821782178217\n",
      "TP: 97.2972972972973\n",
      "Overall: 87.37864077669903\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import operator\n",
    "batch_size =50 \n",
    "level =8\n",
    "\n",
    "def load_model(session, save_path):\n",
    "    \"\"\" Loads a saved TF model from a file.Returns:The inputs placehoder and the prediction operation. \"\"\"\n",
    "    print(\"Loading model from file '%s'...\" % (save_path))\n",
    "    meta_file = save_path + \".meta\"\n",
    "    if not os.path.exists(meta_file):\n",
    "        print(\"ERROR: Expected .meta file '%s', but could not find it.\" % \\\n",
    "        (meta_file))\n",
    "        sys.exit(1) \n",
    "    saver = tf.train.import_meta_graph(meta_file)\n",
    "    save_path = os.path.join(\"./\", save_path) \n",
    "    saver.restore(session, save_path)  \n",
    "    return extract_validation_handles(session)\n",
    "    \n",
    "def load_validation_data(level=0):\n",
    "    global batch_size \n",
    "    \"\"\" Loads the validation data,  Returns: A tuple of the loaded validation data and validation labels. \"\"\"\n",
    "    print(\"Loading validation data...\")\n",
    "    rootfolder = 'sub_features/one_sec' \n",
    "    all_X = []\n",
    "    all_Y = []\n",
    "    all_E = []\n",
    "    for i in range(1,11):\n",
    "        folder = 'noise_level_' + str(10*i)\n",
    "        testX =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/sub_features/one_sec/'+folder+'/testX_pred.npy' ) \n",
    "        testY =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/sub_features/one_sec/testY_pred.npy'  ) \n",
    "        Energy =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/sub_features/one_sec/'+folder+'/Energy_pred.npy' )\n",
    "        #print (np.shape(testX))\n",
    "        all_X.append(testX)\n",
    "        all_Y.append(testY)\n",
    "        all_E.append(Energy) \n",
    "    return (all_X[level], all_Y[level], all_E[level])  \n",
    "\n",
    "def validate_model(session, val_data, x,y, e, phase_train,prob): \n",
    "    \"\"\" Validates the model stored in a session.Returns:The overall validation accuracy for the model. \"\"\"\n",
    "    global batch_size\n",
    "    print(\"Validating model...\")\n",
    "    #y = tf.placeholder(tf.int32, [None, 3]) \n",
    "    predict_op = tf.argmax(prob,1)\n",
    "    correct = tf.equal(predict_op,tf.argmax(y, 1))\n",
    "    acc= tf.reduce_mean(tf.cast(correct, tf.float32))  \n",
    "    val_x, val_y, val_e = val_data\n",
    "    test_correct = session.run(correct,feed_dict={x: val_x, e:val_e,y :val_y , phase_train : True  })\n",
    "    test_acc = session.run(acc,feed_dict={x: val_x, e:val_e,y :val_y , phase_train : True  })\n",
    "    return ( test_acc), test_correct  \n",
    " \n",
    "def extract_validation_handles(session):\n",
    "    \"\"\" Extracts the input and predict_op handles that we use for validation.\n",
    "    Args:\n",
    "      session: The session with the loaded graph.\n",
    "    Returns:\n",
    "      The inputs placeholder, mask placeholder, and the prediction operation. \"\"\" \n",
    "    valid_nodes = tf.get_collection_ref(\"validation_nodes\") \n",
    "    x = valid_nodes[0] \n",
    "    y = valid_nodes[1]  \n",
    "    e = valid_nodes[2]  \n",
    "    phase_train =valid_nodes[3]\n",
    "    prob = valid_nodes[4]\n",
    "    global batch_size \n",
    "    #batch_size = int(x.get_shape()[0])  \n",
    "    # Predict op should also yield integers.\n",
    "    #predict = tf.cast(predict_op, \"int32\") \n",
    "    # Check the shape of the prediction output.\n",
    "    #p_shape = predict.get_shape() \n",
    "    return (x,y,e, phase_train,prob)\n",
    "\n",
    "def each_perform(correct_results,eval_labels ):\n",
    "    label_y=np.argmax(eval_labels,1) \n",
    "    \n",
    "    acc = []\n",
    "    zero = np.where(label_y==0) \n",
    "    correctl=[correct_results[i] for i in zero]\n",
    "    accuracy_zero= np.mean(correctl,dtype=np.float32)\n",
    "    acc.append(accuracy_zero)\n",
    "\n",
    "    one = np.where(label_y==1)\n",
    "    correctg=[correct_results[i] for i in one] \n",
    "    accuracy_one= np.mean(correctg,dtype=np.float32)\n",
    "    acc.append(accuracy_one)\n",
    "\n",
    "    two = np.where(label_y==2)\n",
    "    correctt=[correct_results[i] for i in two] \n",
    "    accuracy_two= np.mean(correctt,dtype=np.float32)\n",
    "    acc.append(accuracy_two) \n",
    "    #print('The accuracy of the linetrip events is %.2f \\n'  %(100*accuracy_zero))\n",
    "    #print('The accuracy of the generator trip events is %.2f \\n' %(100-100*accuracy_one))\n",
    "    #print('The accuracy of the line faults events is %.2f \\n' %(100-100*accuracy_two) )\n",
    "    return acc, correctl,correctg,correctt\n",
    "def reset():\n",
    "    tf.reset_default_graph() \n",
    "level = 5 # level i denotes snr = i+1\n",
    "model_name ='modelA_snr'+str((level)*10)+'_fully'\n",
    "used = [768, 4, 261, 262, 11, 12, 791, 26, 177, 951, 957, 192, 964, 716, 717, 980, 985, 219, 733, 227, 229, 741, 1127, 250, 1135, 752, 753, 1139, 1140, 756, 757, 246, 1146, 1149]\n",
    " \n",
    "with tf.Session() as session:   \n",
    "    best_model = 'E:/05_research/04_deep_learning_model/Save_parameters/modelA/Best_noise_model/'+ model_name #os.path.join(save_path,model_name) \n",
    "    x,y,e,phase_train,prob = load_model(session, best_model)\n",
    "    val_data = load_validation_data(level-1) # the predicted mode\n",
    "    total = [i for i in range(np.shape(val_data[0])[0])]\n",
    "    remain = list(set(total) - set(used)); \n",
    "    accuracy ,correct_results= validate_model(session, val_data, x,y,e,phase_train,prob) \n",
    "    remain_results = np.array([correct_results[i] for i in remain] )\n",
    "    labels = [val_data[1][i] for i in remain] \n",
    "    acc,correct_l,correct_g,correct_t= each_perform(remain_results,labels )  \n",
    "session.close()\n",
    "reset() \n",
    "id_True =  np.nonzero(remain_results==True) \n",
    "overall_acc = (len(id_True[0])/len(remain_results)) \n",
    "print ('LT:', 100*np.mean( correct_l))\n",
    "print ('GT:', 100*np.mean( correct_g))\n",
    "print ('TP:', 100*np.mean( correct_t))\n",
    "print ('Overall:', 100*overall_acc) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
