{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file 'E:/05_research/04_deep_learning_model/Save_parameters/modelA/fully_best/modelA_ratio100_set01'...\n",
      "INFO:tensorflow:Restoring parameters from E:/05_research/04_deep_learning_model/Save_parameters/modelA/fully_best/modelA_ratio100_set01\n",
      "Loading validation data...\n",
      "Validating model...\n",
      "Overall validation accuracy is 0.888273 \n",
      "\n",
      "LT: 82.8042328042328\n",
      "GT: 85.30805687203792\n",
      "TP: 96.96969696969697\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import time \n",
    "batch_size =50 \n",
    "\n",
    "def load_model(session, save_path):\n",
    "    \"\"\" Loads a saved TF model from a file.Returns:The inputs placehoder \"\"\"\n",
    "    print(\"Loading model from file '%s'...\" % (save_path))\n",
    "    meta_file = save_path + \".meta\"\n",
    "    if not os.path.exists(meta_file):\n",
    "        print(\"ERROR: Expected .meta file '%s', but could not find it.\" % \\\n",
    "        (meta_file))\n",
    "        sys.exit(1) \n",
    "    saver = tf.train.import_meta_graph(meta_file)\n",
    "    save_path = os.path.join(\"./\", save_path) \n",
    "    saver.restore(session, save_path)  \n",
    "    return extract_validation_handles(session)\n",
    "    \n",
    "def load_validation_data( model,filename):\n",
    "    '''load the testing dataset with the process and the name of testing file''' \n",
    "    global batch_size \n",
    "    \"\"\" Loads the validation data,  Returns: A tuple of the loaded validation data and validation labels. \"\"\"\n",
    "    print(\"Loading validation data...\")\n",
    "    folder = 'sub_features/'+ filename  \n",
    "    if model ==1: # SP process\n",
    "        testX =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/'+folder+'/testX_pred.npy' ) \n",
    "        testY =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/'+folder+'/testY_pred.npy'  ) \n",
    "        Energy =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/'+folder+'/Energy_pred.npy' )\n",
    "    elif model==2: # NS process\n",
    "        testX =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/'+folder+'/testX_no.npy' ) \n",
    "        testY =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/'+folder+'/testY_no.npy' ) \n",
    "        Energy =np.load('E:/identification_data/01_PSSE_datasets/Dataset/saved_data_jupyter/'+folder+'/Energy_no.npy'  ) \n",
    "    batch_size =np.shape(testX)[0]  \n",
    "    return (testX,testY,Energy)  \n",
    "\n",
    "def validate_model(session, val_data, x,y, e, phase_train,prob ): \n",
    "    \"\"\" Validates the model stored in a session.Returns:The overall validation accuracy for the model. \"\"\"\n",
    "    global batch_size\n",
    "    print(\"Validating model...\") \n",
    "    predict_op = tf.argmax(prob, 1)\n",
    "    correct = tf.equal(predict_op,tf.argmax(y, 1))\n",
    "    acc= tf.reduce_mean(tf.cast(correct, tf.float32))  \n",
    "    val_x, val_y, val_e = val_data\n",
    "    test_correct = session.run(correct,feed_dict={x: val_x, e:val_e,y :val_y , phase_train : True  })\n",
    "    test_acc = session.run(acc,feed_dict={x: val_x, e:val_e,y :val_y , phase_train : True  })\n",
    "    return ( test_acc), test_correct  \n",
    "\n",
    "def extract_validation_handles(session):\n",
    "    \"\"\" Extracts the input and predict_op handles that we use for validation.\n",
    "    Args:\n",
    "      session: The session with the loaded graph.\n",
    "    Returns:\n",
    "      The inputs placeholder  \"\"\" \n",
    "    valid_nodes = tf.get_collection_ref(\"validation_nodes\") \n",
    "    x = valid_nodes[0] \n",
    "    y = valid_nodes[1]\n",
    "    e = valid_nodes[2]  \n",
    "    phase_train =valid_nodes[3]\n",
    "    prob = valid_nodes[4]\n",
    "    global batch_size  \n",
    "    return (x,y,e, phase_train,prob)\n",
    "\n",
    "def each_perform(correct_results,eval_labels ):\n",
    "    label_y=np.argmax(eval_labels,1) \n",
    "    \n",
    "    acc = []\n",
    "    zero = np.where(label_y==0) \n",
    "    correctl=[correct_results[i] for i in zero]\n",
    "    accuracy_zero= np.mean(correctl,dtype=np.float32)\n",
    "    acc.append(accuracy_zero)\n",
    "\n",
    "    one = np.where(label_y==1)\n",
    "    correctg=[correct_results[i] for i in one] \n",
    "    accuracy_one= np.mean(correctg,dtype=np.float32)\n",
    "    acc.append(accuracy_one)\n",
    "\n",
    "    two = np.where(label_y==2)\n",
    "    correctt=[correct_results[i] for i in two] \n",
    "    accuracy_two= np.mean(correctt,dtype=np.float32)\n",
    "    acc.append(accuracy_two) \n",
    "    return acc, correctl,correctg,correctt\n",
    "\n",
    "\n",
    "def reset():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "  \n",
    "  \n",
    "model = 1 # model = 1: SP process; model = 2: NS process\n",
    "folder ='fully_best/modelA_ratio100_set01'#'modelA_fully3'##''modelA_ratio100_set3'#'modelA_ratio80_set4'#'modelA_ratio50_set2'#'modelA_ratio30_set2'#'modelA_fully3'#'modelA_ratio24_set05'#'modelA_small04' # 'modelA_fully3' #,'save2','save3','save4','save5','save6','save7','save8','save9','save10','save11','save12','save13','save14','save15' ]\n",
    "testname = 'total'\n",
    "with tf.Session() as session:  \n",
    "    best_model = 'E:/05_research/04_deep_learning_model/Save_parameters/modelA/'+folder# os.path.join(save_path,model_name)\n",
    "    x,y,e,phase_train,prob = load_model(session, best_model)\n",
    "    val_data = load_validation_data(model, testname) # the predicted mode\n",
    "    accuracy ,correct_results= validate_model(session, val_data, x,y,e,phase_train,prob)\n",
    "    print (\"Overall validation accuracy is %f \\n\" %(accuracy))\n",
    "    acc,correct_l,correct_g,correct_t= each_perform(correct_results,val_data[1] ) \n",
    "    #reset() \n",
    "    session.close()\n",
    "each_perform(correct_results,val_data[1] )     \n",
    "print ('LT:', 100*np.mean( correct_l))\n",
    "print ('GT:', 100*np.mean( correct_g))\n",
    "print ('TP:', 100*np.mean( correct_t))\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  18,   23,   25,   31,   33,   38,   64,   69,   70,   74,   77,\n",
       "          78,   82,   83,   85,   88,   90,  101,  104,  118,  143,  156,\n",
       "         162,  200,  244,  250,  280,  286,  315,  374,  425,  490,  547,\n",
       "         572,  601,  619,  620,  623,  634,  638,  640,  641,  642,  644,\n",
       "         647,  650,  660,  686,  712,  734,  736,  742,  743,  744,  787,\n",
       "         813,  814,  815,  816,  822,  824,  826,  827,  829,  830,  831,\n",
       "         834,  836,  838,  839,  840,  841,  842,  843,  845,  848,  849,\n",
       "         852,  853,  855,  857,  860,  870,  874,  882,  884,  888,  905,\n",
       "         906,  914,  920,  924,  925,  928,  930,  931,  932,  933,  934,\n",
       "         953,  975,  987,  998,  999, 1022, 1023, 1027, 1043, 1051, 1061,\n",
       "        1090, 1115, 1134, 1152, 1153, 1155, 1176, 1179, 1180, 1181, 1182,\n",
       "        1184, 1185, 1188, 1195, 1196, 1197, 1218, 1224, 1230, 1232, 1249,\n",
       "        1250, 1251, 1252, 1253, 1256, 1257, 1258, 1259, 1260], dtype=int64),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_false =  np.nonzero(correct_results==False)  \n",
    "id_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_f  =[  18,   23,   25,   31,   33,   38,   64,   69,   70,   74,   77,\n",
    "          78,   82,   83,   85,   88,   90,  101,  104,  118,  143,  156,\n",
    "         162,  200,  244,  250,  280,  286,  315,  374,  425,  490,  547,\n",
    "         572,  601,  619,  620,  623,  634,  638,  640,  641,  642,  644,\n",
    "         647,  650,  660,  686,  712,  734,  736,  742,  743,  744,  787,\n",
    "         813,  814,  815,  816,  822,  824,  826,  827,  829,  830,  831,\n",
    "         834,  836,  838,  839,  840,  841,  842,  843,  845,  848,  849,\n",
    "         852,  853,  855,  857,  860,  870,  874,  882,  884,  888,  905,\n",
    "         906,  914,  920,  924,  925,  928,  930,  931,  932,  933,  934,\n",
    "         953,  975,  987,  998,  999, 1022, 1023, 1027, 1043, 1051, 1061,\n",
    "        1090, 1115, 1134, 1152, 1153, 1155, 1176, 1179, 1180, 1181, 1182,\n",
    "        1184, 1185, 1188, 1195, 1196, 1197, 1218, 1224, 1230, 1232, 1249,\n",
    "        1250, 1251, 1252, 1253, 1256, 1257, 1258, 1259, 1260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id1 = [i for i in id_f if i < 169]\n",
    "id2 = [i for i in id_f if i >= 169 and i < (169+404)]\n",
    "id3 = [i for i in id_f if i >= (169+404) and i < (169+404+378)]\n",
    "id4 = [i for i in id_f if i >= (169+404+378) and i < (169+404+378+107)]\n",
    "id5 = [i for i in id_f if i >= (169+404+378+107) and i < (169+404+378+107+58)]\n",
    "id6 = [i for i in id_f if i >= (169+404+378+107+58) and i < 1262]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.3905325443787\n",
      "97.27722772277228\n",
      "82.8042328042328\n",
      "90.65420560747664\n",
      "94.82758620689656\n",
      "80.13698630136986\n"
     ]
    }
   ],
   "source": [
    "acc1 = (1-len(id1)/169)*100 ; print ( acc1)\n",
    "acc2 = (1-len(id2)/404)*100 ; print ( acc2)\n",
    "acc3 = (1-len(id3)/378)*100 ; print ( acc3)\n",
    "acc4 = (1-len(id4)/107)*100 ; print ( acc4)\n",
    "acc5 = (1-len(id5)/58)*100 ; print ( acc5)\n",
    "acc6 = (1-len(id6)/146)*100 ; print ( acc6)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
